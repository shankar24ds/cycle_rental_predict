{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from scipy.stats import zscore\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/df_intermediate.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anamalous Observations Detection\n",
    "- outliers will be found manually and treated as Na\n",
    "    - 'check_point5' the drop from mid Aug - Nov seems anamalous and needs to be handled.\n",
    "    - 'check_point6' has an outlier value of 9999 that needs to be handled.\n",
    "    - 'check_point15' has zero values from Apr - mid May which seems anamalous and needs to be handled.\n",
    "    - 'check_point15' has one zero value that needs to be handled.\n",
    "- outliers will be imputed with modern missing value handling techniques like MICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # removing outliers using sliding window and z-threshold\n",
    "\n",
    "# df_cp = df.iloc[:,0:22] # filtering checkpoints dataset\n",
    "# z_score_threshold = 1\n",
    "# window_size = 30\n",
    "# for column in df_cp_afterMay.columns[1:]:\n",
    "#     z_scores = zscore(df_cp_afterMay[column])\n",
    "#     outlier_flags = np.zeros(len(df_cp_afterMay))\n",
    "#     for i in range(window_size, len(df_cp_afterMay) - window_size):\n",
    "#         window_z_scores = z_scores[i - window_size:i + window_size + 1]\n",
    "#         if all(np.abs(window_z_scores) > z_score_threshold):\n",
    "#             outlier_flags[i] = 1\n",
    "#     df_cp_afterMay.loc[outlier_flags.astype(bool), column] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[(df['date'] > '2015-08-20') & (df['date'] < '2015-11-10'), 'check_point5'] = np.nan\n",
    "df.loc[df['check_point6']==9999, 'check_point6'] = np.nan\n",
    "df.loc[(df['date'] >= '2015-04-02') & (df['date'] <= '2015-05-14'), 'check_point15']  = np.nan\n",
    "df.loc[df['check_point9']==0, 'check_point9'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Imputation by Chained Equations (MICE)\n",
    "- To compute target variable(which is sum of all checkpoint values) we have to impute the values. Traditional modes of imputation like mean/median imputation can't be performed as there are number of research papers that advise against it. So, implementing more advanced, straightforward and robust technique like MICE. if the data is missing completely at random(MCAR) or missing at random(MAR), MICE can be performed. Multiple imputation is considered a good approach for data sets with a large amount of missing data. Multiple imputations can produce statistically valid results even when there is a small sample size or a large amount of missing data.\n",
    "- I am going to make use of weather related variable info to predict the missing values with MICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_toimpute = df.drop(columns=['date'])\n",
    "\n",
    "imputer = IterativeImputer(random_state=0, min_value=0, max_iter=100)\n",
    "df_imputed = imputer.fit_transform(df_toimpute)\n",
    "\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=df_toimpute.columns)\n",
    "df_imputed['date'] = df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before and After MICE implementation\n",
    "## check_point5\n",
    "![a](../images/1_after_MICE.png)\n",
    "![b](../images/1_before_MICE.png)\n",
    "## check_point6\n",
    "![c](../images/2_after_MICE.png)\n",
    "![d](../images/2_before_MICE.png)\n",
    "## check_point15\n",
    "![e](../images/3_after_MICE.png)\n",
    "![f](../images/3_before_MICE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_imputed['sum_checkpointCount'] = df_imputed[df_imputed.columns[0:21]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exporting the processed data\n",
    "df_imputed.to_csv(\"../data/processed/df_imputed.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
